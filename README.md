# FairVis: Visual Analytics for Discovering Intersectional Bias in Machine Learning

**FairVis** is a visual analytics system that allows users to audit their classification models for intersectional bias. Users can generate subgroups of their data and investigate if a model is underperforming for certain populations.

* Try a **[live demo](https://khsakib.github.io/SidVis_demo/)**!
* Read the **[full paper](https://arxiv.org/abs/1904.05419)**.
